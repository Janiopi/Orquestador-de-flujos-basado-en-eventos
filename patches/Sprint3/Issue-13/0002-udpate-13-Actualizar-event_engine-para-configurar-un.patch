From ddd6e9cea8ea362b3fe43408e65fcbc900a5936f Mon Sep 17 00:00:00 2001
From: janiopi <janio072003@hotmail.com>
Date: Sun, 29 Jun 2025 00:25:22 -0500
Subject: [PATCH 2/3] udpate[#13]: Actualizar event_engine para configurar un
 observer por flujo

---
 src/event_engine.py | 63 +++++++++++++++++++++++++++------------------
 1 file changed, 38 insertions(+), 25 deletions(-)

diff --git a/src/event_engine.py b/src/event_engine.py
index aad6c9c..7fdd81a 100644
--- a/src/event_engine.py
+++ b/src/event_engine.py
@@ -6,7 +6,10 @@ import yaml
 import redis
 import logging
 import threading
+import subprocess
 from src.workflow_deps import check_dependencies, update_workflow_state
+from src.workflow_deps import deploy
+
 
 # Configura el sistema para escribir un log en un archivo y en la consola
 logging.basicConfig(
@@ -31,35 +34,35 @@ class FileEventHandler(watchdog.events.FileSystemEventHandler):
         if not event.is_directory:
             logger.info(f"Archivo creado: {event.src_path}")
             for wf in self.workflows:
-                if wf["event"] == "file_created" and event.src_path.startswith(
-                    wf["path"]
-                ):
-                    if check_dependencies(wf):
-                        action = wf["action"].replace("<file>", event.src_path)
-                        logger.info(f"Ejecutando acci贸n: {action}")
-                        exit_code = os.system(action)
-                        workflow_id = wf.get("id", "")
-                        status = "success" if exit_code == 0 else "failed"
-                        update_workflow_state(workflow_id, status)
-                    else:
-                        logger.warning(f"Dependencias no cumplidas para workflow {wf.get('id', '')}")
-                elif wf["event"] == "k8s_deploy" and event.src_path.startswith(wf.get("path", "")):
-                    if check_dependencies(wf):
-                        action = wf["action"].replace("<manifest>", wf["manifest"])
-                        logger.info(f"Ejecutando acci贸n: {action}")
-                        exit_code = os.system(action)
-                        workflow_id = wf.get("id", "")
-                        status = "success" if exit_code == 0 else "failed"
-                        update_workflow_state(workflow_id, status)
-                    else:
-                        logger.warning(f"Dependencias no cumplidas para workflow {wf.get('id', '')}")
+                if wf["event"] == "file_created" :
+                    esta_en_directorio = event.src_path.startswith(wf["path"])
+                    es_recursivo = wf.get("recursive", True)
+                    es_directorio_exacto = os.path.dirname(event.src_path) == wf["path"].rstrip("/")
+                    if esta_en_directorio and (es_recursivo or es_directorio_exacto):
+                        if check_dependencies(wf):
+                            if wf.get("action_type") == "script":
+                                action = wf["action"].replace("<file>", event.src_path)
+                                logger.info(f"Ejecutando acci贸n: {action}")
+                                result = subprocess.run(action, shell=True, capture_output=True, text=True)
+                                status = "success" if result.returncode == 0 else "failed"
+                                update_workflow_state(wf.get("id",""), status)
+                            elif wf.get("action_type") == "kubernetes":
+                                logger.info(f"Ejecutando acci贸n de Kubernetes: {wf['manifest']}")
+                                succes = deploy(wf["manifest"])
+                                status = "success" if succes else "failed"
+                                update_workflow_state(wf.get("id", ""), status)
+                        else:
+                            logger.warning(f"Dependencias no cumplidas para workflow {wf.get('id', '')}")
 
 
 # Carga la configuracion de workflows desde un YAML
 def load_workflows(config_path):
     try:
         with open(config_path) as f:
-            return yaml.safe_load(f)["workflows"]
+            workflows = yaml.safe_load(f)["workflows"]
+            for wf in workflows:
+                wf["id"] = wf.get("id", f"workflow_{id(wf)}")
+            return workflows
     except FileNotFoundError:
         logger.error(f"No se encontro {config_path}")
         exit(1)
@@ -81,7 +84,9 @@ def listen_redis(queue, workflows):
                 for wf in workflows:
                     if wf["event"] == "message_received" and wf["queue"] == queue:
                         logger.info(f"Ejecutando accion: {wf['action']}")
-                        os.system(wf["action"])
+                        result = subprocess.run(wf["action"], shell=True, capture_output=True, text=True)
+                        status = "success" if result.returncode == 0 else "failed"
+                        update_workflow_state(wf.get("id", ""), status)
     except redis.RedisError as e:
         logger.error(f"Error de Redis: {e}")
         exit(1)
@@ -90,19 +95,27 @@ def listen_redis(queue, workflows):
 if __name__ == "__main__": # pragma: no cover
     data_dir = "/app/data"
     config_path = "/app/docs/workflows.yaml"
+    redis_url = "redis://localhost:6379/0"
+
     if not os.path.exists(data_dir):
         logger.error(f"Directorio  {data_dir} no existe")
         exit(1)
     if not os.path.exists(config_path):
         logger.error(f"No se encontro {config_path} ")
         exit(1)
+
     workflows = load_workflows(config_path)
+
     # File observer
     observer = PollingObserver()
-    observer.schedule(FileEventHandler(workflows), path=data_dir, recursive=False)
+    for wf in workflows:
+        if wf["event"] == "file_created":
+            recursive = wf.get("recursive", True)
+            observer.schedule(FileEventHandler(workflows), path=wf["path"], recursive=recursive)
     observer.start()
     time.sleep(2)
     logger.info(f"Monitoreando: {data_dir}")
+
     # Redis listener
     for wf in workflows:
         if wf["event"] == "message_received":
-- 
2.34.1

